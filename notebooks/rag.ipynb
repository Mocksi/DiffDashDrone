{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Fill the environmental variable with your own OpenAI API key\n",
    "# See: https://platform.openai.com/account/api-keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='repo-embeddings')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(\"http://localhost:6333\", prefer_grpc=True)\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename                                            message  \\\n",
      "count              7737054                                            7737054   \n",
      "unique                8005                                               1000   \n",
      "top     b'.browserslistrc'  b'Update dependency doorkeeper to v5.6.8 (#281...   \n",
      "freq                  1000                                               7824   \n",
      "\n",
      "                                             author_email  \\\n",
      "count                                             7737054   \n",
      "unique                                                 72   \n",
      "top     b'29139614+renovate[bot]@users.noreply.github....   \n",
      "freq                                              1764394   \n",
      "\n",
      "                                               hash bug_spot_likelihood  \\\n",
      "count                                       7737054             7737054   \n",
      "unique                                         1000                 212   \n",
      "top     b'456597dae5251af841e46ab0608e0d44a7de1197'            b'0.273'   \n",
      "freq                                           7824             7497000   \n",
      "\n",
      "                        commit_timestamp  \n",
      "count                            7737054  \n",
      "unique                               999  \n",
      "top     b'2023-10-23 15:46:21 +0000 UTC'  \n",
      "freq                               15519  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME=\"repo-embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models as rest\n",
    "\n",
    "vector_size = 1536\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        \"content\": rest.VectorParams(\n",
    "            distance=rest.Distance.COSINE,\n",
    "            size=vector_size,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oaclient = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct, Payload, Filter\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "def get_embeddings(text, model=\"text-embedding-ada-002\", encoding_format=\"float\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   time.sleep(0.5) # Prevent getting rate limited \n",
    "   return oaclient.embeddings.create(input = [text], model=model, encoding_format=encoding_format).data\n",
    "\n",
    "async def add_to_client(sdf):\n",
    "    for _, row in sdf.iterrows():\n",
    "        formatted_output = f\"\"\"\n",
    "        filename: {row['filename']},\n",
    "        message: {row['message']},\n",
    "        author_email: {row['author_email']},\n",
    "        hash: {row['hash']},\n",
    "        bug_spot_likelihood: {row['bug_spot_likelihood']},\n",
    "        commit_timestamp: {row['commit_timestamp']}\n",
    "        \"\"\"\n",
    "        embeddings = get_embeddings(formatted_output)\n",
    "        points=[\n",
    "            rest.PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector={\"content\": embedding.embedding},\n",
    "                payload={f\"#{str(row['hash'])}_#{str(row['filename'])}\": formatted_output}\n",
    "            ) \n",
    "            for embedding in embeddings\n",
    "        ]\n",
    "        client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "    print(f\"processed:#{sdf.head(1).index} to: #{sdf.tail(1).index}\")\n",
    "\n",
    "async def process():\n",
    "    tasks = [add_to_client(df[i:i+chunk_size]) for i in range(0, len(df), chunk_size)]\n",
    "    for task in tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "        await task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#await process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_RESULTS = 100\n",
    "SCORE_THRESHOLD = 0.700\n",
    "def rag(question: str, n_points: int = 30) -> str:\n",
    "    embeddings = get_embeddings(question)\n",
    "    embedded_query = embeddings[0].embedding\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=(\n",
    "            \"content\", embedded_query\n",
    "        ),\n",
    "        limit=n_points,\n",
    "    )\n",
    "    results = [result for result in results if round(result.score, 3) >= SCORE_THRESHOLD]\n",
    "\n",
    "    context = \"\\n\".join(str(r) for r in results[:TOP_N_RESULTS])\n",
    "\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a software architect. \n",
    "    Answer the following question using the provided context. \n",
    "    If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "    \n",
    "    Question: {question.strip()}\n",
    "    \n",
    "    Context: you have the following list of Git Commits: {context.strip()}.\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    completion = oaclient.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": metaprompt},\n",
    "        ],\n",
    "        timeout=10.0,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context does not provide any specific information or details about a list of Git commits.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"Give me a summary about the context\", n_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
