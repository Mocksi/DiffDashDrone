{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Fill the environmental variable with your own OpenAI API key\n",
    "# See: https://platform.openai.com/account/api-keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"x\"\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='repo-embeddings')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(\"http://localhost:6333\", prefer_grpc=True)\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename                                            message  \\\n",
      "count              7780009                                            7780009   \n",
      "unique                8025                                               1000   \n",
      "top     b'.browserslistrc'  b'Add validation specs to `CustomFilter` model...   \n",
      "freq                  1000                                               7875   \n",
      "\n",
      "                    author_email                                         hash  \\\n",
      "count                    7780009                                      7780009   \n",
      "unique                        64                                         1000   \n",
      "top     b'matt@jankowski.online'  b'12bed81187dd5b041a735af8e9cb5a5f96b4b75a'   \n",
      "freq                     2161983                                         7875   \n",
      "\n",
      "       bug_spot_likelihood                  commit_timestamp  \n",
      "count              7780009                           7780009  \n",
      "unique                 201                               999  \n",
      "top               b'0.253'  b'2023-10-23 15:46:21 +0000 UTC'  \n",
      "freq               7549000                             15519  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME=\"repo-embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models as rest\n",
    "\n",
    "vector_size = 1536\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        \"content\": rest.VectorParams(\n",
    "            distance=rest.Distance.COSINE,\n",
    "            size=vector_size,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oaclient = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.asyncio import tqdm, trange\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct, Payload, Filter\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "def get_embeddings(text, model=\"text-embedding-ada-002\", encoding_format=\"float\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   time.sleep(0.1) # Prevent getting rate limited \n",
    "   return oaclient.embeddings.create(input=[text], model=model, encoding_format=encoding_format).data\n",
    "\n",
    "async def add_to_client(sdf):\n",
    "    for _, row in sdf.iterrows():\n",
    "        filename = row['filename'].decode('utf-8')  # Decode bytes to string\n",
    "        message = row['message'].decode('utf-8')    # Decode bytes to string\n",
    "        author_email = row['author_email'].decode('utf-8')  # Decode bytes to string\n",
    "        hash_value = row['hash'].decode('utf-8')    # Decode bytes to string\n",
    "\n",
    "        formatted_output = f\"\"\"\n",
    "        filename: {filename},\n",
    "        message: {message},\n",
    "        author_email: {author_email},\n",
    "        hash: {hash_value},\n",
    "        bug_spot_likelihood: {row['bug_spot_likelihood']},\n",
    "        commit_timestamp: {row['commit_timestamp']}\n",
    "        \"\"\"\n",
    "\n",
    "        embeddings = get_embeddings(formatted_output)\n",
    "\n",
    "        points = [\n",
    "            rest.PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector={\"content\": embedding.embedding},\n",
    "                payload={\n",
    "                    \"filename\": filename,\n",
    "                    \"message\": message,\n",
    "                    \"author_email\": author_email,\n",
    "                    \"hash\": hash_value,\n",
    "                    \"bug_spot_likelihood\": str(row['bug_spot_likelihood']),\n",
    "                    \"commit_timestamp\": str(row['commit_timestamp']),\n",
    "                }\n",
    "            )\n",
    "            for embedding in embeddings\n",
    "        ]\n",
    "\n",
    "        client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "\n",
    "async def process():\n",
    "    filtered_df = df[df[\"filename\"].str.decode('utf-8').str.startswith('app')]  # Filter based on decoded string prefix 'app'\n",
    "    tasks = [add_to_client(filtered_df[i:i+chunk_size]) for i in range(0, len(filtered_df), chunk_size)]\n",
    "    STEP_SIZE = 10\n",
    "    for i in tqdm(range(0, len(tasks), STEP_SIZE), desc=\"tasks\"):\n",
    "        taskgroup = tasks[i:i+STEP_SIZE]\n",
    "        for task in tqdm(asyncio.as_completed(taskgroup), total=len(taskgroup), desc=\"taskgroup\"):\n",
    "            await task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:28<00:00, 32.87s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:48<00:00, 34.81s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:56<00:00, 35.65s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [06:03<00:00, 36.32s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [06:20<00:00, 38.05s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [06:03<00:00, 36.34s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [06:34<00:00, 39.48s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [07:06<00:00, 42.63s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [06:15<00:00, 37.52s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:27<00:00, 32.76s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:26<00:00, 32.61s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:23<00:00, 32.38s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:25<00:00, 32.57s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:50<00:00, 35.01s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:37<00:00, 33.72s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:18<00:00, 31.80s/it]\n",
      "taskgroup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:23<00:00, 32.34s/it]\n",
      "tasks:   1%|██▏                                                                                                                                                                                                                                                   | 17/1926 [1:39:28<175:28:28, 330.91s/it]"
     ]
    }
   ],
   "source": [
    "# await process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_RESULTS = 100\n",
    "SCORE_THRESHOLD = 0.700\n",
    "def rag(question: str, n_points: int = 30) -> str:\n",
    "    embeddings = get_embeddings(question)\n",
    "    embedded_query = embeddings[0].embedding\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=(\n",
    "            \"content\", embedded_query\n",
    "        ),\n",
    "        limit=n_points,\n",
    "    )\n",
    "    results = [result for result in results if round(result.score, 3) >= SCORE_THRESHOLD]\n",
    "\n",
    "    context = \"\\n\".join(str(r) for r in results[:TOP_N_RESULTS])\n",
    "\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a software architect. \n",
    "    Answer the following question using the provided context. \n",
    "    If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "    \n",
    "    Question: {question.strip()}\n",
    "    \n",
    "    Context: you have the following list of Git Commits: {context.strip()}.\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    completion = oaclient.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": metaprompt},\n",
    "        ],\n",
    "        timeout=10.0,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"Give me a summary about the context\", n_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
